name: Run ETL Using Python

on:
  workflow_dispatch:
    inputs:
      archivos:
        description: "Archivos a ser procesados"
        default: "yellow_tripdata_2020-01.parquet,yellow_tripdata_2021-01.parquet,yellow_tripdata_2022-01.parquet"
      class:
        type: choice
        description: Modulo python
        required: true
        options:
          - src/taxis_etl_prft/DemoS3.py
          - src/taxis_etl_prft/SimpleApp.py

env:
  TAXIS_ETL_FILES: ${{ github.event.inputs.archivos }}
  TAXIS_ETL_DOWNLOAD_FOLDER: downloads
  TAXIS_ETL_DOWNLOAD_SOURCE: s3
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_S3_BUCKET: prft-etl-testing

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout project sources
      uses: actions/checkout@v3
    - uses: actions/setup-python@v3
      with:
        python-version: '3.10'
    - name: Setup JDK
      uses: actions/setup-java@v3
      with:
        distribution: temurin
        java-version: '17'
    - uses: vemonet/setup-spark@v1
      with:
        spark-version: '3.4.0'
        hadoop-version: '3'
    - run: spark-submit --version
    - name: Install python dependencies
      run: pip install -e .
    - run: mkdir ./downloads
    - name: Run python script '${{ github.event.inputs.class }}'
      run: python ${{ github.event.inputs.class }}
    - name: Archive ETL results
      uses: actions/upload-artifact@v3
      with:
        name: results
        path: results
